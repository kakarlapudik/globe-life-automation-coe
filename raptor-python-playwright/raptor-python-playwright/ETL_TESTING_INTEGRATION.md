# ETL Testing Framework Integration - RAPTOR

## ðŸš€ NEW: Polars-Powered ETL Testing (v2.0)

**RAPTOR now includes a high-performance Polars-powered ETL testing framework!**

### Performance Improvements
- **5-100x faster** than pandas-based testing
- **50-80% memory reduction**
- **Native parallel processing**
- **Streaming support** for datasets larger than memory
- **Lazy evaluation** with query optimization

### Quick Start with Polars
```python
import polars as pl
from raptor.etl import PolarsValidator, PolarsDataComparator

# High-performance validation
df = pl.read_csv("data.csv")
validator = PolarsValidator()
validator.expect_column_not_null("user_id")
validator.expect_column_unique("email")
results = validator.validate(df)

# Lightning-fast comparison
comparator = PolarsDataComparator()
diff = comparator.compare(staging_df, prod_df, key_columns=["id"])
```

ðŸ“– **[Complete Polars ETL Testing Guide](POLARS_ETL_TESTING_GUIDE.md)**

---

## Overview

Integration of open-source ETL testing frameworks with RAPTOR's custom ETL framework to provide comprehensive data pipeline testing, validation, and quality assurance capabilities.

## Integrated Open-Source Frameworks

### 1. **Great Expectations** âœ…
- **Purpose**: Data validation and profiling
- **Use Case**: Validate data quality at each ETL stage
- **Integration**: Native Python library
- **Website**: https://greatexpectations.io/

### 2. **dbt (data build tool)** âœ…
- **Purpose**: Data transformation testing
- **Use Case**: Test SQL transformations and data models
- **Integration**: Python adapter
- **Website**: https://www.getdbt.com/

### 3. **pytest-datatest** âœ…
- **Purpose**: Data testing framework
- **Use Case**: Unit tests for data pipelines
- **Integration**: pytest plugin
- **Website**: https://pypi.org/project/pytest-datatest/

### 4. **Pandera** âœ…
- **Purpose**: DataFrame validation
- **Use Case**: Schema validation for pandas DataFrames
- **Integration**: Native Python library
- **Website**: https://pandera.readthedocs.io/

### 5. **Soda Core** âœ…
- **Purpose**: Data quality testing
- **Use Case**: SQL-based data quality checks
- **Integration**: Python SDK
- **Website**: https://www.soda.io/

### 6. **Datafold** (Optional) ðŸ”„
- **Purpose**: Data diff and regression testing
- **Use Case**: Compare data across environments
- **Integration**: API-based
- **Website**: https://www.datafold.com/

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RAPTOR ETL Framework                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Extractors  â”‚  â”‚ Transformers â”‚  â”‚   Loaders    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                  â”‚                  â”‚               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                            â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         ETL Testing Integration Layer                   â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚    Great     â”‚  â”‚     dbt      â”‚  â”‚   Pandera    â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ Expectations â”‚  â”‚   Testing    â”‚  â”‚  Validation  â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚  Soda Core   â”‚  â”‚    pytest    â”‚  â”‚   Custom     â”‚ â”‚  â”‚
â”‚  â”‚  â”‚   Checks     â”‚  â”‚  datatest    â”‚  â”‚  Validators  â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         Test Reporting & Monitoring                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Implementation Plan

### Phase 1: Great Expectations Integration (Week 1-2)
- Set up Great Expectations context
- Create expectation suites for data validation
- Integrate with ETL pipeline steps
- Generate data quality reports

### Phase 2: Pandera Integration (Week 2-3)
- Define DataFrame schemas
- Add schema validation to transformers
- Implement custom validators
- Error handling and reporting

### Phase 3: Soda Core Integration (Week 3-4)
- Configure Soda checks
- SQL-based quality tests
- Integration with data sources
- Automated check execution

### Phase 4: dbt Integration (Week 4-5)
- Set up dbt project structure
- Create data models and tests
- Integration with transformation layer
- Test execution and reporting

### Phase 5: pytest-datatest Integration (Week 5-6)
- Write data unit tests
- Integration with pytest framework
- CI/CD pipeline integration
- Test coverage reporting

## Key Features

### 1. Data Quality Validation
```python
from raptor.etl.testing import DataQualityTester

# Great Expectations validation
tester = DataQualityTester(framework="great_expectations")
tester.expect_column_values_to_not_be_null("user_id")
tester.expect_column_values_to_be_unique("email")
tester.expect_column_values_to_be_between("age", min_value=0, max_value=150)
```

### 2. Schema Validation
```python
from raptor.etl.testing import SchemaValidator
import pandera as pa

# Pandera schema validation
schema = pa.DataFrameSchema({
    "user_id": pa.Column(int, pa.Check.greater_than(0)),
    "email": pa.Column(str, pa.Check.str_matches(r"^[\w\.-]+@[\w\.-]+\.\w+$")),
    "created_at": pa.Column(pa.DateTime)
})

validator = SchemaValidator(schema)
validated_df = validator.validate(dataframe)
```

### 3. SQL Quality Checks
```python
from raptor.etl.testing import SodaChecker

# Soda Core checks
checker = SodaChecker(data_source="postgresql")
checker.add_check("row_count > 1000")
checker.add_check("missing_count(email) = 0")
checker.add_check("duplicate_count(user_id) = 0")
results = checker.run_checks()
```

### 4. Transformation Testing
```python
from raptor.etl.testing import TransformationTester

# dbt-style transformation tests
tester = TransformationTester()
tester.test_unique("user_id")
tester.test_not_null(["user_id", "email"])
tester.test_relationships("orders", "user_id", "users", "id")
tester.test_accepted_values("status", ["active", "inactive", "pending"])
```

### 5. Data Comparison
```python
from raptor.etl.testing import DataComparator

# Compare data across environments
comparator = DataComparator()
diff = comparator.compare(
    source_df=staging_data,
    target_df=production_data,
    key_columns=["user_id"],
    compare_columns=["email", "name", "status"]
)
```

## Benefits

### For Test Automation
- **Comprehensive Coverage**: Test data at every stage of ETL
- **Early Detection**: Catch data quality issues before they propagate
- **Automated Validation**: Reduce manual data verification
- **Regression Testing**: Ensure data consistency across changes

### For Data Engineers
- **Industry Standards**: Use proven open-source tools
- **Flexibility**: Choose the right tool for each use case
- **Scalability**: Handle large datasets efficiently
- **Documentation**: Auto-generated data quality reports

### For Organizations
- **Data Governance**: Enforce data quality standards
- **Compliance**: Meet regulatory requirements
- **Cost Savings**: Reduce data quality incidents
- **Trust**: Increase confidence in data pipelines

## Dependencies

### Required
```bash
# Core ETL testing frameworks
great-expectations>=0.18.0
pandera>=0.17.0
soda-core>=3.0.0
pytest-datatest>=0.11.0

# Data processing
pandas>=2.0.0
numpy>=1.24.0

# Database connectivity
sqlalchemy>=2.0.0
psycopg2-binary>=2.9.0

# Testing
pytest>=7.4.0
pytest-cov>=4.1.0
```

### Optional
```bash
# dbt integration
dbt-core>=1.7.0
dbt-postgres>=1.7.0

# Advanced features
datafold-sdk>=1.0.0
deepdiff>=6.7.0

# Visualization
plotly>=5.17.0
matplotlib>=3.8.0
```

## Configuration Example

```yaml
# raptor/config/etl_testing.yaml
etl_testing:
  enabled: true
  
  great_expectations:
    enabled: true
    context_root_dir: "tests/great_expectations"
    data_docs_enabled: true
    
  pandera:
    enabled: true
    strict: true
    coerce: true
    
  soda:
    enabled: true
    data_source: "postgresql"
    checks_dir: "tests/soda_checks"
    
  dbt:
    enabled: true
    project_dir: "dbt_project"
    profiles_dir: "~/.dbt"
    
  pytest_datatest:
    enabled: true
    test_dir: "tests/data_tests"
    
  reporting:
    format: ["html", "json"]
    output_dir: "test_reports/etl"
    include_data_docs: true
```

## Usage Examples

### Example 1: Complete ETL Pipeline with Testing

```python
from raptor.etl import ETLPipeline
from raptor.etl.testing import (
    GreatExpectationsValidator,
    PanderaValidator,
    SodaChecker
)

# Create pipeline
pipeline = ETLPipeline("user_data_pipeline")

# Add extraction
extractor = DatabaseExtractor(connection_string="postgresql://...")
pipeline.add_extractor(extractor)

# Add Great Expectations validation after extraction
ge_validator = GreatExpectationsValidator(
    expectation_suite_name="user_data_suite"
)
ge_validator.expect_column_values_to_not_be_null("user_id")
ge_validator.expect_column_values_to_be_unique("email")
pipeline.add_validator(ge_validator)

# Add transformation
transformer = DataCleaner(rules=[...])
pipeline.add_transformer(transformer)

# Add Pandera schema validation after transformation
schema = pa.DataFrameSchema({
    "user_id": pa.Column(int, pa.Check.greater_than(0)),
    "email": pa.Column(str, pa.Check.str_matches(r"^[\w\.-]+@[\w\.-]+\.\w+$")),
    "age": pa.Column(int, pa.Check.in_range(0, 150))
})
pandera_validator = PanderaValidator(schema)
pipeline.add_validator(pandera_validator)

# Add loading
loader = DatabaseLoader(connection_string="postgresql://...")
pipeline.add_loader(loader)

# Add Soda checks after loading
soda_checker = SodaChecker(data_source="target_db")
soda_checker.add_check("row_count > 1000")
soda_checker.add_check("missing_count(email) = 0")
pipeline.add_checker(soda_checker)

# Execute pipeline with testing
result = await pipeline.execute()

# Check results
if result.is_successful():
    print(f"Pipeline completed successfully")
    print(f"Data quality score: {result.data_quality_report.quality_score:.2%}")
    print(f"All validations passed: {result.all_tests_passed}")
else:
    print(f"Pipeline failed: {result.job.error_message}")
    print(f"Failed validations: {result.failed_validations}")
```

### Example 2: Data Quality Testing Suite

```python
import pytest
from raptor.etl.testing import DataQualityTestSuite

class TestUserDataQuality(DataQualityTestSuite):
    """Test suite for user data quality."""
    
    @pytest.fixture
    def user_data(self):
        """Load user data for testing."""
        return self.load_data("users.csv")
    
    def test_no_null_user_ids(self, user_data):
        """Test that user_id column has no null values."""
        self.assert_column_not_null(user_data, "user_id")
    
    def test_unique_emails(self, user_data):
        """Test that email addresses are unique."""
        self.assert_column_unique(user_data, "email")
    
    def test_valid_email_format(self, user_data):
        """Test that emails match valid format."""
        self.assert_column_matches_pattern(
            user_data, 
            "email", 
            r"^[\w\.-]+@[\w\.-]+\.\w+$"
        )
    
    def test_age_in_valid_range(self, user_data):
        """Test that age values are in valid range."""
        self.assert_column_in_range(user_data, "age", 0, 150)
    
    def test_row_count_threshold(self, user_data):
        """Test that dataset has minimum row count."""
        self.assert_row_count_greater_than(user_data, 1000)
    
    def test_no_duplicate_records(self, user_data):
        """Test that there are no duplicate records."""
        self.assert_no_duplicates(user_data, ["user_id"])
```

### Example 3: Schema Evolution Testing

```python
from raptor.etl.testing import SchemaEvolutionTester

# Test schema changes
tester = SchemaEvolutionTester()

# Define old schema
old_schema = {
    "user_id": "int",
    "email": "string",
    "name": "string"
}

# Define new schema
new_schema = {
    "user_id": "int",
    "email": "string",
    "first_name": "string",  # Changed from 'name'
    "last_name": "string",   # New field
    "created_at": "datetime" # New field
}

# Test schema compatibility
compatibility = tester.check_compatibility(old_schema, new_schema)

if compatibility.is_backward_compatible:
    print("Schema change is backward compatible")
else:
    print(f"Breaking changes detected: {compatibility.breaking_changes}")
```

### Example 4: Data Lineage Testing

```python
from raptor.etl.testing import DataLineageTester

# Test data lineage
lineage_tester = DataLineageTester()

# Define expected lineage
expected_lineage = {
    "source": "raw_users",
    "transformations": [
        "clean_emails",
        "normalize_names",
        "calculate_age"
    ],
    "destination": "users_dim"
}

# Validate lineage
lineage_result = lineage_tester.validate_lineage(
    pipeline_name="user_etl",
    expected_lineage=expected_lineage
)

assert lineage_result.is_valid, f"Lineage mismatch: {lineage_result.differences}"
```

## Integration with RAPTOR Test Framework

```python
# raptor/tests/test_etl_integration.py
import pytest
from raptor.etl import ETLPipeline
from raptor.etl.testing import ETLTestRunner

class TestETLPipeline:
    """Integration tests for ETL pipelines."""
    
    @pytest.fixture
    def etl_pipeline(self):
        """Create ETL pipeline for testing."""
        pipeline = ETLPipeline("test_pipeline")
        # Configure pipeline...
        return pipeline
    
    def test_pipeline_execution(self, etl_pipeline):
        """Test complete pipeline execution."""
        runner = ETLTestRunner(etl_pipeline)
        result = runner.run()
        
        assert result.is_successful()
        assert result.data_quality_report.quality_score >= 0.95
        assert result.all_tests_passed
    
    def test_data_quality_validations(self, etl_pipeline):
        """Test data quality validations."""
        runner = ETLTestRunner(etl_pipeline)
        result = runner.run_validations()
        
        assert len(result.failed_validations) == 0
        assert result.validation_coverage >= 0.90
    
    def test_schema_compliance(self, etl_pipeline):
        """Test schema compliance."""
        runner = ETLTestRunner(etl_pipeline)
        result = runner.validate_schemas()
        
        assert result.all_schemas_valid
        assert len(result.schema_violations) == 0
```

## Reporting

### Data Quality Dashboard
```python
from raptor.etl.testing import DataQualityDashboard

# Generate comprehensive dashboard
dashboard = DataQualityDashboard()
dashboard.add_pipeline_results(pipeline_result)
dashboard.add_validation_results(validation_results)
dashboard.add_test_results(test_results)

# Generate HTML report
dashboard.generate_report(
    output_path="reports/data_quality_dashboard.html",
    include_charts=True,
    include_details=True
)
```

### Test Coverage Report
```python
from raptor.etl.testing import TestCoverageReporter

# Generate test coverage report
reporter = TestCoverageReporter()
coverage = reporter.calculate_coverage(
    pipeline=pipeline,
    test_suite=test_suite
)

print(f"Data validation coverage: {coverage.validation_coverage:.1%}")
print(f"Schema coverage: {coverage.schema_coverage:.1%}")
print(f"Transformation coverage: {coverage.transformation_coverage:.1%}")
print(f"Overall coverage: {coverage.overall_coverage:.1%}")
```

## Best Practices

1. **Test Early and Often**: Validate data at each ETL stage
2. **Use Multiple Frameworks**: Combine tools for comprehensive coverage
3. **Automate Testing**: Integrate with CI/CD pipelines
4. **Monitor Quality**: Track data quality metrics over time
5. **Document Expectations**: Clearly define data quality requirements
6. **Version Control**: Track changes to data schemas and tests
7. **Performance Testing**: Test with production-scale data
8. **Error Handling**: Gracefully handle validation failures

## Timeline

- **Week 1-2**: Great Expectations integration
- **Week 2-3**: Pandera integration
- **Week 3-4**: Soda Core integration
- **Week 4-5**: dbt integration
- **Week 5-6**: pytest-datatest integration
- **Week 6-7**: Testing and documentation
- **Week 7-8**: CI/CD integration and examples

**Total**: 8 weeks for complete integration

## Success Criteria

- [ ] All 5 frameworks integrated and working
- [ ] Comprehensive test coverage (>90%)
- [ ] Documentation and examples complete
- [ ] CI/CD pipeline integration
- [ ] Performance benchmarks met
- [ ] User acceptance testing passed

## Conclusion

This integration brings industry-standard ETL testing capabilities to RAPTOR, combining the best open-source tools with our custom framework. Teams can now ensure data quality, validate transformations, and catch issues early in the development cycle.

**Status**: Ready for implementation
**Priority**: High
**Complexity**: Medium-High

---

**Next Steps**: Begin Phase 1 implementation with Great Expectations integration.
